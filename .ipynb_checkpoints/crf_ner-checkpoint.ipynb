{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use Conditional Random Fields (CRFs) to solve Named Entity Recognition (NER) problem. NER is a common task in natural language processing systems. It serves for extraction such entities from the text as persons, organizations, locations, etc. We will build a NER to recognize named entities from Twitter.\n",
    "\n",
    "For example, we want to extract persons' and organizations' names from the text. Than for the input text:\n",
    "\n",
    "    Ian Goodfellow works for Google Brain\n",
    "\n",
    "a NER model needs to provide the following sequence of tags:\n",
    "\n",
    "    B-PER I-PER    O     O   B-ORG  I-ORG\n",
    "\n",
    "Where *B-* and *I-* prefixes stand for the beginning and inside of the entity, while *O* stands for out of tag or no tag. Markup with the prefix scheme is called *BIO markup*. This markup is introduced for distinguishing of consequent entities with similar types.\n",
    "\n",
    "We will use [sklearn-crfsuite](https://sklearn-crfsuite.readthedocs.io/en/latest/) to build CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time \n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "data_path = \"./data/twitter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/- Load the Twitter Named Entity Recognition corpus\n",
    "\n",
    "We will work with a corpus, which contains tweets with NE tags. Every line of a file contains a pair of a token (word/punctuation symbol) and a tag, separated by a whitespace. Different tweets are separated by an empty line.\n",
    "\n",
    "## 1) Read data\n",
    "The function *read_data* reads a corpus from the *file_path* and returns two lists: one with tokens and one with the corresponding tags. You need to complete this function by adding a code, which will replace a user's nickname to `<USR>` token and any URL to `<URL>` token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    \n",
    "    tweet_tokens = []\n",
    "    tweet_tags = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            if tweet_tokens:\n",
    "                tokens.append(tweet_tokens)\n",
    "                tags.append(tweet_tags)\n",
    "            tweet_tokens = []\n",
    "            tweet_tags = []\n",
    "        else:\n",
    "            token, tag = line.split()\n",
    "\n",
    "            if token.startswith('http://') or token.startswith(\"https://\"):\n",
    "                token = \"<URL>\"\n",
    "            if token.startswith(\"@\"):\n",
    "                token = \"<USR>\"\n",
    "            \n",
    "            tweet_tokens.append(token)\n",
    "            tweet_tags.append(tag)\n",
    "            \n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can load three separate parts of the dataset:\n",
    " - *train* data for training the model;\n",
    " - *validation* data for evaluation and hyperparameters tuning;\n",
    " - *test* data for final evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_tags = read_data(os.path.join(data_path, 'train.txt'))\n",
    "validation_tokens, validation_tags = read_data(os.path.join(data_path, 'validation.txt'))\n",
    "test_tokens, test_tags = read_data(os.path.join(data_path, 'test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Features engineering\n",
    "\n",
    "Unlike the case of neural netwokrs, it is necessary to build some features before training a CRF. In fact we use our knowledge about natural language and about the task that we want to achieve to build some features that represents the words of the corpus. For example is we want to build a model that detects proper nouns, then using \"Starts with Capital Letter\" will be a good choie of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        # If the word is not the first in the sentence\n",
    "        # Use the previous word to build some features\n",
    "        word1 = sent[i-1]\n",
    "        features.update({\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        # If the word is not the last in the sentence\n",
    "        # Use the next word to build some features\n",
    "        word1 = sent[i+1]\n",
    "        features.update({\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_tokens]\n",
    "y_train = train_tags\n",
    "\n",
    "X_val = [sent2features(s) for s in validation_tokens]\n",
    "y_val = validation_tags\n",
    "\n",
    "X_test = [sent2features(s) for s in test_tokens]\n",
    "y_test = test_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=None,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III/-Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-musicartist',\n",
       " 'I-musicartist',\n",
       " 'B-product',\n",
       " 'I-product',\n",
       " 'B-company',\n",
       " 'B-person',\n",
       " 'B-other',\n",
       " 'I-other',\n",
       " 'B-facility',\n",
       " 'I-facility',\n",
       " 'B-sportsteam',\n",
       " 'B-geo-loc',\n",
       " 'I-geo-loc',\n",
       " 'I-company',\n",
       " 'I-person',\n",
       " 'B-movie',\n",
       " 'I-movie',\n",
       " 'B-tvshow',\n",
       " 'I-tvshow',\n",
       " 'I-sportsteam']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3698941654120787"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    B-company      0.600     0.214     0.316        84\n",
      "    I-company      0.600     0.225     0.327        40\n",
      "   B-facility      0.625     0.319     0.423        47\n",
      "   I-facility      0.667     0.426     0.520        61\n",
      "    B-geo-loc      0.802     0.491     0.609       165\n",
      "    I-geo-loc      0.647     0.423     0.512        52\n",
      "      B-movie      0.500     0.125     0.200         8\n",
      "      I-movie      0.333     0.200     0.250        10\n",
      "B-musicartist      0.000     0.000     0.000        27\n",
      "I-musicartist      0.000     0.000     0.000        24\n",
      "      B-other      0.518     0.282     0.365       103\n",
      "      I-other      0.254     0.194     0.220        93\n",
      "     B-person      0.548     0.385     0.452       104\n",
      "     I-person      0.517     0.470     0.492        66\n",
      "    B-product      0.286     0.071     0.114        28\n",
      "    I-product      0.290     0.150     0.198        60\n",
      " B-sportsteam      0.500     0.065     0.114        31\n",
      " I-sportsteam      0.200     0.083     0.118        12\n",
      "     B-tvshow      0.000     0.000     0.000         7\n",
      "     I-tvshow      0.000     0.000     0.000         5\n",
      "\n",
      "    micro avg      0.541     0.298     0.384      1027\n",
      "    macro avg      0.394     0.206     0.261      1027\n",
      " weighted avg      0.515     0.298     0.370      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
